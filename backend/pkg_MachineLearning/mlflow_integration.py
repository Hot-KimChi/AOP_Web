import uuid
import json
import datetime
import logging
import sys
import sklearn
from flask import session
from pkg_SQL.database import SQL


class AOP_MLflowTracker:
    """
    machine_learning.pyì™€ ì™„ë²½ í†µí•©ëœ MLflow ì¶”ì  ì‹œìŠ¤í…œ
    AOP ì‹œìŠ¤í…œì— íŠ¹í™”ëœ ML ì‹¤í—˜ ì¶”ì  ë° ê´€ë¦¬
    """

    def __init__(self):
        self.username = session.get("username")
        self.password = session.get("password")

        if not self.username or not self.password:
            raise ValueError("ì‚¬ìš©ì ì¸ì¦ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

        try:
            self.db = SQL(
                username=self.username,
                password=self.password,
                database="AOP_MLflow_Tracking",
            )
            self.tracking_enabled = True
        except Exception as e:
            logging.warning(f"MLflow tracking disabled: {e}")
            self.tracking_enabled = False
            self.db = None

        self.logger = logging.getLogger("AOP_MLflowTracker")
        self.current_run_uuid = None

    def start_training_run(self, model_name, experiment_name="Est_zt_Training"):
        """machine_learning.pyì˜ í›ˆë ¨ ì‹œì‘ ì‹œ í˜¸ì¶œ (ìë™ ì‹¤í—˜ ìƒì„± í¬í•¨)"""
        if not self.tracking_enabled:
            return None

        try:
            # ğŸ†• ê°œì„ : ì‹¤í—˜ ìë™ ìƒì„± ë˜ëŠ” ì¡°íšŒ
            experiment_id = self._ensure_experiment_exists(experiment_name)
            if experiment_id is None:
                self.logger.error(
                    f"Failed to create or find experiment: {experiment_name}"
                )
                return None

            # ìƒˆ ì‹¤í–‰ UUID ìƒì„±
            self.current_run_uuid = str(uuid.uuid4()).replace("-", "")

            # ì‹¤í–‰ ì‹œì‘ ê¸°ë¡
            query = """
                INSERT INTO ml_runs (
                    run_uuid, experiment_id, user_id, run_name, 
                    run_type, model_name, source_code_version, start_time
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """

            run_name = (
                f"{model_name}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
            )
            source_version = f"python{sys.version_info.major}.{sys.version_info.minor}_sklearn{sklearn.__version__}"

            self.db.execute_query(
                query,
                (
                    self.current_run_uuid,
                    experiment_id,
                    self.username,
                    run_name,
                    "training",
                    model_name,
                    source_version,
                    datetime.datetime.now(),
                ),
            )

            self.logger.info(
                f"Training run started: {self.current_run_uuid[:8]}... for {model_name}"
            )
            return self.current_run_uuid

        except Exception as e:
            self.logger.error(f"Failed to start training run: {e}")
            return None

    def _ensure_experiment_exists(self, experiment_name):
        """
        ì‹¤í—˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìë™ ìƒì„±

        Returns:
            int: experiment_id, ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # 1. ê¸°ì¡´ ì‹¤í—˜ ì¡°íšŒ
            exp_query = (
                "SELECT experiment_id FROM ml_experiments WHERE experiment_name = ?"
            )
            exp_result = self.db.execute_query(exp_query, (experiment_name,))

            if not exp_result.empty:
                # ê¸°ì¡´ ì‹¤í—˜ ì¡´ì¬
                experiment_id = int(exp_result.iloc[0]["experiment_id"])
                self.logger.info(
                    f"Found existing experiment: {experiment_name} (ID: {experiment_id})"
                )

                # ğŸ†• ì‹¤í—˜ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
                self._update_experiment_activity(experiment_name)
                return experiment_id

            # 2. ìƒˆ ì‹¤í—˜ ìƒì„±
            self.logger.info(f"Creating new experiment: {experiment_name}")

            create_query = """
                INSERT INTO ml_experiments 
                (experiment_name, artifact_location, lifecycle_stage, creation_time, last_update_time)
                VALUES (?, ?, ?, GETDATE(), GETDATE())
            """

            artifact_location = f"/models/artifacts/{experiment_name}"

            self.db.execute_query(
                create_query, (experiment_name, artifact_location, "active")
            )

            # 3. ìƒì„±ëœ ì‹¤í—˜ ID ì¡°íšŒ
            exp_result = self.db.execute_query(exp_query, (experiment_name,))

            if not exp_result.empty:
                experiment_id = int(exp_result.iloc[0]["experiment_id"])
                self.logger.info(
                    f"Created new experiment: {experiment_name} (ID: {experiment_id})"
                )
                return experiment_id
            else:
                self.logger.error(
                    f"Failed to retrieve created experiment: {experiment_name}"
                )
                return None

        except Exception as e:
            self.logger.error(f"Failed to ensure experiment exists: {e}")
            return None

    def _update_experiment_activity(self, experiment_name):
        """ì‹¤í—˜ì˜ ë§ˆì§€ë§‰ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        try:
            update_query = """
                UPDATE ml_experiments 
                SET last_update_time = GETDATE()
                WHERE experiment_name = ?
            """
            self.db.execute_query(update_query, (experiment_name,))
            self.logger.debug(f"Updated experiment activity: {experiment_name}")

        except Exception as e:
            # ì—…ë°ì´íŠ¸ ì‹¤íŒ¨í•´ë„ ì „ì²´ í”„ë¡œì„¸ìŠ¤ëŠ” ê³„ì† ì§„í–‰
            self.logger.warning(f"Failed to update experiment activity: {e}")

    def log_data_info(self, feature_data, target_data):
        """ë°ì´í„° ì •ë³´ ë¡œê¹…"""
        if not self.tracking_enabled or not self.current_run_uuid:
            return

        try:
            # ë°ì´í„° í˜•íƒœ ì •ë³´
            data_shape_info = (
                f"Features: {feature_data.shape}, Target: {target_data.shape}"
            )

            # íŒŒë¼ë¯¸í„°ë¡œ ì €ì¥
            params = [
                ("features_count", str(feature_data.shape[1]), "data"),
                ("samples_count", str(feature_data.shape[0]), "data"),
                ("target_shape", str(target_data.shape), "data"),
                (
                    "feature_names",
                    (
                        ",".join(feature_data.columns.tolist())
                        if hasattr(feature_data, "columns")
                        else "unknown"
                    ),
                    "data",
                ),
            ]

            for param_key, param_value, param_type in params:
                query = """
                    INSERT INTO ml_params (run_uuid, param_key, param_value, param_type)
                    VALUES (?, ?, ?, ?)
                """
                self.db.execute_query(
                    query,
                    (self.current_run_uuid, param_key, param_value, param_type),
                )

            # ì‹¤í–‰ ì •ë³´ ì—…ë°ì´íŠ¸
            update_query = "UPDATE ml_runs SET data_shape_info = ? WHERE run_uuid = ?"
            self.db.execute_query(
                update_query,
                (data_shape_info, self.current_run_uuid),
            )

            self.logger.info(f"Data info logged: {data_shape_info}")

        except Exception as e:
            self.logger.error(f"Failed to log data info: {e}")

    def log_preprocessing_info(self, model_type, preprocessing_steps=None):
        """ì „ì²˜ë¦¬ ì •ë³´ ë¡œê¹…"""
        if not self.tracking_enabled or not self.current_run_uuid:
            return

        try:
            params = [
                ("preprocessing_model_type", model_type, "preprocessing"),
                (
                    "preprocessing_timestamp",
                    datetime.datetime.now().isoformat(),
                    "preprocessing",
                ),
            ]

            if preprocessing_steps:
                params.append(
                    (
                        "preprocessing_steps",
                        json.dumps(preprocessing_steps),
                        "preprocessing",
                    )
                )

            for param_key, param_value, param_type in params:
                query = """
                    INSERT INTO ml_params (run_uuid, param_key, param_value, param_type)
                    VALUES (?, ?, ?, ?)
                """
                self.db.execute_query(
                    query,
                    (self.current_run_uuid, param_key, param_value, param_type),
                )

            self.logger.info(f"Preprocessing info logged for model type: {model_type}")

        except Exception as e:
            self.logger.error(f"Failed to log preprocessing info: {e}")

    def log_model_params(self, model):
        """ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…"""
        if not self.tracking_enabled or not self.current_run_uuid:
            return

        try:
            if hasattr(model, "get_params"):
                params = model.get_params()

                for param_key, param_value in params.items():
                    query = """
                        INSERT INTO ml_params (run_uuid, param_key, param_value, param_type)
                        VALUES (?, ?, ?, ?)
                    """
                    self.db.execute_query(
                        query,
                        (
                            self.current_run_uuid,
                            param_key,
                            str(param_value)[:1000],
                            "model",
                        ),
                    )

                self.logger.info(f"Model parameters logged: {len(params)} params")

        except Exception as e:
            self.logger.error(f"Failed to log model params: {e}")

    def log_training_result(self, training_result):
        """machine_learning.pyì˜ training_result ë¡œê¹…"""
        if not self.tracking_enabled or not self.current_run_uuid:
            return

        try:
            # ë©”íŠ¸ë¦­ ë¡œê¹…
            metrics = [
                (
                    "train_cv_score",
                    training_result.get("train_cv_score", 0.0),
                    "performance",
                ),
                (
                    "validation_cv_score",
                    training_result.get("validation_cv_score", 0.0),
                    "performance",
                ),
                ("test_score", training_result.get("test_score", 0.0), "performance"),
                ("cv_folds", training_result.get("cv_folds", 5), "data_quality"),
            ]

            for metric_key, metric_value, metric_type in metrics:
                if metric_value is not None:
                    query = """
                        INSERT INTO ml_metrics (run_uuid, metric_key, value, metric_type)
                        VALUES (?, ?, ?, ?)
                    """
                    self.db.execute_query(
                        query,
                        (
                            self.current_run_uuid,
                            metric_key,
                            float(metric_value),
                            metric_type,
                        ),
                    )

            self.logger.info(
                f"Training result logged successfully: {self.current_run_uuid[:8]}..."
            )

        except Exception as e:
            self.logger.error(f"Failed to log training result: {e}")

    def end_run(self, status="FINISHED", error_message=None):
        """ì‹¤í–‰ ì¢…ë£Œ"""
        if not self.tracking_enabled or not self.current_run_uuid:
            return

        try:
            query = """
                UPDATE ml_runs 
                SET end_time = ?, status = ?
                WHERE run_uuid = ?
            """

            self.db.execute_query(
                query,
                (datetime.datetime.now(), status, self.current_run_uuid),
            )

            if error_message:
                # ì—ëŸ¬ ì •ë³´ë¥¼ íŒŒë¼ë¯¸í„°ë¡œ ì €ì¥
                error_query = """
                    INSERT INTO ml_params (run_uuid, param_key, param_value, param_type)
                    VALUES (?, ?, ?, ?)
                """
                self.db.execute_query(
                    error_query,
                    (
                        self.current_run_uuid,
                        "error_message",
                        str(error_message)[:1000],
                        "system",
                    ),
                )

            self.logger.info(
                f"Run ended: {self.current_run_uuid[:8]}... with status: {status}"
            )
            self.current_run_uuid = None

        except Exception as e:
            self.logger.error(f"Failed to end run: {e}")

    def _normalize_model_name(self, model_name, prediction_type="intensity"):
        """
        ëª¨ë¸ëª…ì„ ì˜ˆì¸¡ íƒ€ì…ë³„ ë°ì´í„°ë² ì´ìŠ¤ ë“±ë¡ëª…ìœ¼ë¡œ ë³€í™˜

        Args:
            model_name (str): model_selection.pyì—ì„œ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ëª…
            prediction_type (str): 'intensity', 'power', 'temperature'

        Returns:
            str: ë°ì´í„°ë² ì´ìŠ¤ì— ë“±ë¡í•  í‘œì¤€í™”ëœ ëª¨ë¸ëª…
        """
        base_mapping = {
            "RandomForestRegressor": "RandomForest_AOP",
            "Gradient_Boosting": "GradientBoosting_AOP",
            "Histogram-based_Gradient_Boosting": "HistGradientBoosting_AOP",
            "XGBoost": "XGBoost_AOP",
            "VotingRegressor": "VotingRegressor_AOP",
            "LinearRegression": "LinearRegression_AOP",
            "PolynomialFeatures_with_linear_regression": "PolynomialLinear_AOP",
            "Ridge_regularization(L2_regularization)": "Ridge_AOP",
            "DecisionTreeRegressor": "DecisionTree_AOP",
            "DL_DNN": "DL_DNN_AOP",
        }

        base_name = base_mapping.get(model_name, f"{model_name}_AOP")

        # ì˜ˆì¸¡ íƒ€ì…ë³„ ëª¨ë¸ëª… ìƒì„±
        prediction_suffix = prediction_type.capitalize()
        return f"{base_name}_{prediction_suffix}"

    def _serialize_model(self, model_object):
        """
        ëª¨ë¸ ê°ì²´ë¥¼ ë°”ì´ë„ˆë¦¬ë¡œ ì§ë ¬í™”í•˜ê³  ì••ì¶•

        Args:
            model_object: í›ˆë ¨ëœ ëª¨ë¸ ê°ì²´

        Returns:
            tuple: (compressed_binary_data, compression_type, checksum, original_size)
        """
        import pickle
        import gzip
        import hashlib

        try:
            # 1. ëª¨ë¸ ì§ë ¬í™”
            model_binary = pickle.dumps(model_object)
            original_size = len(model_binary)

            # 2. gzip ì••ì¶•
            compressed_binary = gzip.compress(model_binary)

            # 3. MD5 ì²´í¬ì„¬ ê³„ì‚°
            checksum = hashlib.md5(compressed_binary).hexdigest()

            return compressed_binary, "gzip", checksum, original_size

        except Exception as e:
            self.logger.error(f"Model serialization failed: {e}")
            return None, None, None, None

    def _deserialize_model(self, binary_data, compression_type="gzip"):
        """
        ì••ì¶•ëœ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì—ì„œ ëª¨ë¸ ê°ì²´ ë³µì›

        Args:
            binary_data (bytes): ì••ì¶•ëœ ëª¨ë¸ ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            compression_type (str): ì••ì¶• íƒ€ì… ("gzip")

        Returns:
            object: ë³µì›ëœ ëª¨ë¸ ê°ì²´, ì‹¤íŒ¨ ì‹œ None
        """
        import pickle
        import gzip

        try:
            # 1. ì••ì¶• í•´ì œ
            if compression_type == "gzip":
                model_binary = gzip.decompress(binary_data)
            else:
                model_binary = binary_data

            # 2. ëª¨ë¸ ê°ì²´ ë³µì›
            model_object = pickle.loads(model_binary)

            return model_object

        except Exception as e:
            self.logger.error(f"Model deserialization failed: {e}")
            return None

    def _extract_model_metadata(self, model_object, model_name):
        """
        ëª¨ë¸ ê°ì²´ì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ

        Args:
            model_object: í›ˆë ¨ëœ ëª¨ë¸ ê°ì²´
            model_name (str): ëª¨ë¸ëª…

        Returns:
            dict: ëª¨ë¸ ë©”íƒ€ë°ì´í„° (DB ì»¬ëŸ¼ì— ì§ì ‘ ë§¤í•‘)
        """
        import json

        # ê¸°ë³¸ ë©”íƒ€ë°ì´í„°
        metadata = {
            "python_version": "unknown",
            "sklearn_version": "unknown",
            "model_class_name": type(model_object).__name__,
            "model_parameters": "{}",
            "feature_names": "[]",
            "feature_count": 0,
        }

        try:
            # Python ë²„ì „ í™•ì¸
            import sys

            metadata["python_version"] = (
                f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
            )

            # sklearn ë²„ì „ í™•ì¸
            import sklearn

            metadata["sklearn_version"] = sklearn.__version__

            # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            if hasattr(model_object, "get_params"):
                params = model_object.get_params()
                # JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
                serializable_params = {}
                for key, value in params.items():
                    try:
                        json.dumps(value)  # ì§ë ¬í™” ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸
                        serializable_params[key] = value
                    except (TypeError, ValueError):
                        serializable_params[key] = str(value)

                metadata["model_parameters"] = json.dumps(
                    serializable_params, ensure_ascii=False
                )

            # íŠ¹ì„± ê°œìˆ˜ ë° ì´ë¦„
            if hasattr(model_object, "n_features_in_"):
                metadata["feature_count"] = int(model_object.n_features_in_)

            if hasattr(model_object, "feature_names_in_"):
                feature_names = (
                    model_object.feature_names_in_.tolist()
                    if hasattr(model_object.feature_names_in_, "tolist")
                    else list(model_object.feature_names_in_)
                )
                metadata["feature_names"] = json.dumps(
                    feature_names, ensure_ascii=False
                )
            else:
                # feature_names_in_ì´ ì—†ëŠ” ê²½ìš° AOP ê¸°ë³¸ feature ëª…ë“¤ ì‚¬ìš©
                default_feature_names = [
                    "TxFrequencyHz",
                    "TxFocusLocCm",
                    "NumTxElements",
                    "TxpgWaveformStyle",
                    "ProbeNumTxCycles",
                    "ElevAperIndex",
                    "IsTxChannelModulationEn",
                    "IsTxAperModulationEn",
                    "probePitchCm",
                    "probeRadiusCm",
                    "probeElevAperCm0",
                    "probeElevAperCm1",
                    "probeElevFocusRangCm",
                    "probeElevFocusRangCm1",
                ]
                # n_features_in_ê³¼ ì¼ì¹˜í•˜ëŠ” ë§Œí¼ë§Œ ì‚¬ìš©
                if hasattr(model_object, "n_features_in_"):
                    feature_count = int(model_object.n_features_in_)
                    feature_names = default_feature_names[:feature_count]
                    metadata["feature_names"] = json.dumps(
                        feature_names, ensure_ascii=False
                    )
                    self.logger.info(
                        f"Used default feature names for {feature_count} features"
                    )

        except Exception as e:
            self.logger.warning(f"Could not extract full model metadata: {e}")

        return metadata

    def _ensure_model_exists(self, normalized_model_name):
        """
        ë“±ë¡ëœ ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±

        Args:
            normalized_model_name (str): ì •ê·œí™”ëœ ëª¨ë¸ëª…

        Returns:
            int: registered_model_id, ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # 1. ê¸°ì¡´ ëª¨ë¸ ì¡°íšŒ
            model_query = (
                "SELECT model_id FROM ml_registered_models WHERE model_name = ?"
            )
            model_result = self.db.execute_query(model_query, (normalized_model_name,))

            if not model_result.empty:
                return int(model_result.iloc[0]["model_id"])

            # 2. ìƒˆ ëª¨ë¸ ìƒì„±
            from datetime import datetime

            insert_query = """
                INSERT INTO ml_registered_models (model_name, creation_time, last_updated_time)
                OUTPUT INSERTED.model_id
                VALUES (?, ?, ?)
            """
            current_time = datetime.now()

            result = self.db.execute_query(
                insert_query,
                (normalized_model_name, current_time, current_time),
                return_type="insert",
            )

            if (
                isinstance(result, dict)
                and "insert_id" in result
                and result["insert_id"] is not None
            ):
                registered_model_id = result["insert_id"]
                self.logger.info(
                    f"Created new registered model: {normalized_model_name} (ID: {registered_model_id})"
                )
                return registered_model_id
            else:
                self.logger.error(
                    f"Failed to create registered model: {normalized_model_name} - result: {result}"
                )
                return None

        except Exception as e:
            self.logger.error(f"Error ensuring model exists: {e}")
            return None

    def _get_next_version_number(self, registered_model_id):
        """
        ë‹¤ìŒ ëª¨ë¸ ë²„ì „ ë²ˆí˜¸ ê³„ì‚°

        Args:
            registered_model_id (int): ë“±ë¡ëœ ëª¨ë¸ ID

        Returns:
            int: ë‹¤ìŒ ë²„ì „ ë²ˆí˜¸
        """
        try:
            version_query = """
                SELECT COALESCE(MAX(version_number), 0) + 1 as next_version 
                FROM ml_model_versions 
                WHERE model_id = ?
            """
            result = self.db.execute_query(version_query, (registered_model_id,))

            if not result.empty:
                return int(result.iloc[0]["next_version"])
            else:
                return 1

        except Exception as e:
            self.logger.error(f"Error getting next version number: {e}")
            return 1

    def _create_model_version(
        self,
        registered_model_id,
        version_number,
        binary_data,
        compression_type,
        checksum,
        metadata,
        prediction_type,
        stage,
        description,
    ):
        """
        ìƒˆ ëª¨ë¸ ë²„ì „ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ìƒì„±

        Args:
            registered_model_id (int): ë“±ë¡ëœ ëª¨ë¸ ID
            version_number (int): ë²„ì „ ë²ˆí˜¸
            binary_data (bytes): ì••ì¶•ëœ ëª¨ë¸ ë°”ì´ë„ˆë¦¬
            compression_type (str): ì••ì¶• íƒ€ì…
            checksum (str): MD5 ì²´í¬ì„¬
            metadata (dict): ëª¨ë¸ ë©”íƒ€ë°ì´í„°
            prediction_type (str): ì˜ˆì¸¡ íƒ€ì…
            stage (str): ëª¨ë¸ ìŠ¤í…Œì´ì§€
            description (str): ì„¤ëª…

        Returns:
            int: ìƒì„±ëœ model_version_id, ì‹¤íŒ¨ ì‹œ None
        """
        try:
            from datetime import datetime
            import json

            # ë©”íƒ€ë°ì´í„°ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
            metadata_json = json.dumps(metadata, ensure_ascii=False)

            # SQL Serverì—ì„œ VARBINARY ë°ì´í„° ì‚½ì… ì‹œ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
            insert_query = """
                INSERT INTO ml_model_versions (
                    model_id, version_number, run_uuid, model_binary, model_size_bytes,
                    compression_type, model_format, checksum, prediction_type, target_variable, 
                    stage, description, user_id, python_version, sklearn_version, model_class_name, 
                    model_parameters, feature_names, feature_count,
                    creation_time, last_updated_time
                )
                OUTPUT INSERTED.version_id
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """

            current_time = datetime.now()

            # ë°”ì´ë„ˆë¦¬ ë°ì´í„° í¬ê¸° ë¡œê·¸
            self.logger.info(f"Inserting model binary data: {len(binary_data)} bytes")

            result = self.db.execute_query(
                insert_query,
                (
                    registered_model_id,
                    version_number,
                    self.current_run_uuid,
                    binary_data,  # bytes ê°ì²´ë¥¼ ì§ì ‘ ì „ë‹¬
                    len(binary_data),  # model_size_bytes - ë°”ì´ë„ˆë¦¬ ë°ì´í„° í¬ê¸°
                    compression_type,
                    "pickle",  # model_format - ì§ë ¬í™” í˜•ì‹
                    checksum,
                    prediction_type,
                    f"aop_{prediction_type}_value",  # target_variable - êµ¬ì²´ì  íƒ€ê²Ÿ ë³€ìˆ˜ëª…
                    stage,
                    description,
                    "system",  # user_id - ì‹œìŠ¤í…œ ì‚¬ìš©ìë¡œ ì„¤ì •
                    metadata["python_version"],
                    metadata["sklearn_version"],
                    metadata["model_class_name"],
                    metadata["model_parameters"],
                    metadata["feature_names"],
                    metadata["feature_count"],
                    current_time,
                    current_time,
                ),
                return_type="insert",
            )

            if (
                isinstance(result, dict)
                and "insert_id" in result
                and result["insert_id"] is not None
            ):
                version_id = result["insert_id"]
                self.logger.info(
                    f"Model version created: ID {version_id}, version {version_number}, "
                    f"prediction_type {prediction_type}"
                )
                return version_id
            else:
                self.logger.error(f"Failed to create model version - result: {result}")
                return None

        except Exception as e:
            self.logger.error(f"Error creating model version: {e}")
            return None

    def register_model(
        self,
        model_name,
        model_object,
        training_result,
        prediction_type="intensity",
        stage="None",
        description=None,
    ):
        """
        í›ˆë ¨ ì™„ë£Œ í›„ ëª¨ë¸ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ë°”ì´ë„ˆë¦¬ë¡œ ë“±ë¡ (ì˜µì…˜ 1)

        Args:
            model_name (str): ê¸°ë³¸ ëª¨ë¸ëª… (ì˜ˆ: "XGBoost")
            model_object: í›ˆë ¨ëœ ëª¨ë¸ ê°ì²´
            training_result (dict): í›ˆë ¨ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            prediction_type (str): ì˜ˆì¸¡ íƒ€ì… ('intensity', 'power', 'temperature')
            stage (str): ëª¨ë¸ ìŠ¤í…Œì´ì§€ ("None", "Staging", "Production")
            description (str): ëª¨ë¸ ì„¤ëª…

        Returns:
            int: ìƒì„±ëœ model_version_id, ì‹¤íŒ¨ ì‹œ None
        """
        if not self.tracking_enabled or not self.current_run_uuid:
            self.logger.warning(
                "Model registration skipped: tracking disabled or no active run"
            )
            return None

        try:
            # 1. ëª¨ë¸ëª… ì •ê·œí™” (ì˜ˆì¸¡ íƒ€ì… í¬í•¨)
            normalized_model_name = self._normalize_model_name(
                model_name, prediction_type
            )

            # 2. ë“±ë¡ëœ ëª¨ë¸ ID ì¡°íšŒ ë˜ëŠ” ìƒì„±
            registered_model_id = self._ensure_model_exists(normalized_model_name)
            if registered_model_id is None:
                return None

            # 3. ë‹¤ìŒ ë²„ì „ ë²ˆí˜¸ ê³„ì‚°
            version_number = self._get_next_version_number(registered_model_id)

            # 4. ëª¨ë¸ ë°”ì´ë„ˆë¦¬ ì§ë ¬í™”
            binary_data, compression_type, checksum, original_size = (
                self._serialize_model(model_object)
            )
            if binary_data is None:
                return None

            # 5. ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = self._extract_model_metadata(model_object, model_name)

            # 6. ìƒˆ ëª¨ë¸ ë²„ì „ DB ì €ì¥
            version_id = self._create_model_version(
                registered_model_id,
                version_number,
                binary_data,
                compression_type,
                checksum,
                metadata,
                prediction_type,
                stage,
                description,
            )

            if version_id:
                # 7. í›ˆë ¨ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ì¥
                self._log_model_performance(version_id, training_result)

                # 8. ëª¨ë¸ ë“±ë¡ ì™„ë£Œ ë¡œê·¸
                self.logger.info(
                    f"Model registered in database: {normalized_model_name} v{version_number} (ID: {version_id})"
                )
                return version_id
            else:
                return None

        except Exception as e:
            self.logger.error(f"Failed to register model: {e}")
            return None

    def _log_model_performance(self, version_id, training_result):
        """ëª¨ë¸ ì„±ëŠ¥ ì •ë³´ë¥¼ ml_model_performance í…Œì´ë¸”ì— ì €ì¥"""
        try:
            performance_metrics = [
                ("train_cv_score", training_result.get("train_cv_score"), "train"),
                (
                    "validation_cv_score",
                    training_result.get("validation_cv_score"),
                    "validation",
                ),
                ("test_score", training_result.get("test_score"), "test"),
                ("cv_folds", training_result.get("cv_folds"), "cv"),
            ]

            for metric_name, metric_value, dataset_type in performance_metrics:
                if metric_value is not None:
                    perf_query = """
                        INSERT INTO ml_model_performance (
                            model_version_id, metric_name, metric_value, dataset_type
                        )
                        VALUES (?, ?, ?, ?)
                    """
                    self.db.execute_query(
                        perf_query,
                        (version_id, metric_name, float(metric_value), dataset_type),
                    )

            self.logger.info(f"Performance metrics logged for version_id: {version_id}")

        except Exception as e:
            self.logger.error(f"Failed to log model performance: {e}")

    def _auto_promote_best_model(self, model_id, new_version_id, new_test_score):
        """
        ìƒˆ ëª¨ë¸ì´ ìµœê³  ì„±ëŠ¥ì´ë©´ ìë™ìœ¼ë¡œ Productionìœ¼ë¡œ ìŠ¹ê²©
        ê¸°ì¡´ Production ëª¨ë¸ì€ Stagingìœ¼ë¡œ ê°•ë“±
        """
        try:
            if new_test_score is None:
                return

            # í˜„ì¬ Production ëª¨ë¸ì˜ ì„±ëŠ¥ ì¡°íšŒ
            current_prod_query = """
                SELECT mv.version_id, mp.metric_value
                FROM ml_model_versions mv
                JOIN ml_model_performance mp ON mv.version_id = mp.model_version_id
                WHERE mv.model_id = ? AND mv.stage = 'Production' 
                    AND mp.metric_name = 'test_score'
            """
            current_prod_result = self.db.execute_query(current_prod_query, (model_id,))

            should_promote = False

            if current_prod_result.empty:
                # Production ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìŠ¹ê²©
                should_promote = True
                self.logger.info("No Production model found. Promoting new model.")
            else:
                # ê¸°ì¡´ Production ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ìœ¼ë©´ ìŠ¹ê²©
                current_score = float(current_prod_result.iloc[0]["metric_value"])
                if new_test_score > current_score:
                    should_promote = True
                    current_prod_version_id = int(
                        current_prod_result.iloc[0]["version_id"]
                    )

                    # ê¸°ì¡´ Production ëª¨ë¸ì„ Stagingìœ¼ë¡œ ê°•ë“±
                    demote_query = "UPDATE ml_model_versions SET stage = 'Staging' WHERE version_id = ?"
                    self.db.execute_query(demote_query, (current_prod_version_id,))

                    self.logger.info(
                        f"Demoted version_id {current_prod_version_id} to Staging"
                    )

            if should_promote:
                # ìƒˆ ëª¨ë¸ì„ Productionìœ¼ë¡œ ìŠ¹ê²©
                promote_query = "UPDATE ml_model_versions SET stage = 'Production' WHERE version_id = ?"
                self.db.execute_query(promote_query, (new_version_id,))

                self.logger.info(
                    f"Promoted version_id {new_version_id} to Production (score: {new_test_score})"
                )

        except Exception as e:
            self.logger.error(f"Failed to auto-promote model: {e}")

    def log_prediction(
        self,
        model_version_id,
        input_features,
        prediction_result,
        request_source="unknown",
        prediction_type="intensity",
        processing_time_ms=0,
    ):
        """
        ì˜ˆì¸¡ ê²°ê³¼ë¥¼ aop_prediction_logs í…Œì´ë¸”ì— ë¡œê¹…

        Args:
            model_version_id (int): ì‚¬ìš©ëœ ëª¨ë¸ ë²„ì „ ID
            input_features (dict or str): ì…ë ¥ íŠ¹ì„± (JSONìœ¼ë¡œ ì €ì¥)
            prediction_result (list or str): ì˜ˆì¸¡ ê²°ê³¼ (JSONìœ¼ë¡œ ì €ì¥)
            request_source (str): ìš”ì²­ ì¶œì²˜ ("intensity_estimation", "power_estimation" ë“±)
            prediction_type (str): ì˜ˆì¸¡ íƒ€ì… ("intensity", "power", "temperature")
            processing_time_ms (int): ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ)

        Returns:
            int: ìƒì„±ëœ log_id, ì‹¤íŒ¨ ì‹œ None
        """
        if not self.tracking_enabled:
            return None

        try:
            # JSON í˜•íƒœë¡œ ë³€í™˜
            if isinstance(input_features, dict):
                input_features_json = json.dumps(input_features)
            else:
                input_features_json = str(input_features)

            if isinstance(prediction_result, (list, dict)):
                prediction_result_json = json.dumps(prediction_result)
            else:
                prediction_result_json = str(prediction_result)

            # ì˜ˆì¸¡ ë¡œê·¸ ì €ì¥
            log_query = """
                INSERT INTO aop_prediction_logs (
                    model_version_id, input_features, prediction_result,
                    user_id, request_source, processing_time_ms, prediction_type
                )
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """

            self.db.execute_query(
                log_query,
                (
                    model_version_id,
                    input_features_json,
                    prediction_result_json,
                    self.username,
                    request_source,
                    processing_time_ms,
                    prediction_type,
                ),
            )

            self.logger.info(
                f"Prediction logged: {prediction_type} prediction using model version {model_version_id}"
            )
            return True

        except Exception as e:
            self.logger.error(f"Failed to log prediction: {e}")
            return None

    @classmethod
    def get_best_model_info(cls, model_type=None):
        """ìµœì  ëª¨ë¸ ì •ë³´ ì¡°íšŒ (ê°œì„ ëœ ë²„ì „)"""
        try:
            # ì„ì‹œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì„¸ì…˜ ì •ë³´ í•„ìš”)
            username = session.get("username")
            password = session.get("password")

            if not username or not password:
                return None

            db = SQL(
                username=username, password=password, database="AOP_MLflow_Tracking"
            )

            query = """
                SELECT TOP 1
                    rm.model_name,
                    rm.model_type,
                    mv.version_number,
                    mv.file_path,
                    mp.metric_value as test_score,
                    mv.creation_time,
                    mv.stage,
                    mv.version_id
                FROM ml_registered_models rm
                JOIN ml_model_versions mv ON rm.model_id = mv.model_id
                JOIN ml_model_performance mp ON mv.version_id = mp.model_version_id
                WHERE mp.metric_name = 'test_score'
                    AND mv.stage = 'Production'
                    AND (? IS NULL OR rm.model_type = ?)
                ORDER BY mp.metric_value DESC
            """

            result = db.execute_query(query, (model_type, model_type))

            if not result.empty:
                return result.iloc[0].to_dict()

            return None

        except Exception as e:
            logging.error(f"Failed to get best model info: {e}")
            return None

    @classmethod
    def get_model_by_name(cls, model_name, stage="Production"):
        """ëª¨ë¸ëª…ìœ¼ë¡œ íŠ¹ì • ìŠ¤í…Œì´ì§€ì˜ ëª¨ë¸ ì •ë³´ ì¡°íšŒ"""
        try:
            username = session.get("username")
            password = session.get("password")

            if not username or not password:
                return None

            db = SQL(
                username=username, password=password, database="AOP_MLflow_Tracking"
            )

            query = """
                SELECT TOP 1
                    rm.model_name,
                    rm.model_type,
                    mv.version_number,
                    mv.file_path,
                    mv.stage,
                    mv.version_id,
                    mp.metric_value as test_score
                FROM ml_registered_models rm
                JOIN ml_model_versions mv ON rm.model_id = mv.model_id
                LEFT JOIN ml_model_performance mp ON mv.version_id = mp.model_version_id 
                    AND mp.metric_name = 'test_score'
                WHERE rm.model_name = ?
                    AND mv.stage = ?
                ORDER BY mv.version_number DESC
            """

            result = db.execute_query(query, (model_name, stage))

            if not result.empty:
                return result.iloc[0].to_dict()

            return None

        except Exception as e:
            logging.error(f"Failed to get model by name: {e}")
            return None

    @classmethod
    def log_simple_prediction(
        cls, input_features, prediction_result, prediction_type="regression"
    ):
        """ì˜ˆì¸¡ ê²°ê³¼ ë¡œê¹… (aop_prediction_logs í…Œì´ë¸”ì— ì €ì¥)"""
        try:
            username = session.get("username")
            password = session.get("password")

            if not username or not password:
                return None

            db = SQL(
                username=username, password=password, database="AOP_MLflow_Tracking"
            )

            # ì…ë ¥ íŠ¹ì„±ë“¤ì„ JSON í˜•íƒœë¡œ ì €ì¥
            input_features_json = (
                json.dumps(input_features)
                if isinstance(input_features, dict)
                else str(input_features)
            )

            # ì˜ˆì¸¡ ê²°ê³¼ë„ JSON í˜•íƒœë¡œ ì €ì¥
            prediction_json = (
                json.dumps(prediction_result)
                if not isinstance(prediction_result, str)
                else prediction_result
            )

            query = """
                INSERT INTO aop_prediction_logs 
                (input_features, prediction_result, prediction_type, user_id, 
                 request_source, processing_time_ms)
                VALUES (?, ?, ?, ?, ?, ?)
            """

            # ê¸°ë³¸ê°’ ì„¤ì •
            request_source = f"{prediction_type}_calculation"
            processing_time_ms = 0  # ê³„ì‚° ê¸°ë°˜ì´ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •

            db.execute_query(
                query,
                (
                    input_features_json,
                    prediction_json,
                    prediction_type,
                    username,
                    request_source,
                    processing_time_ms,
                ),
            )
            logging.info(f"Prediction logged for prediction_type: {prediction_type}")
            return True

        except Exception as e:
            logging.error(f"Failed to log prediction: {e}")
            return False

    @classmethod
    def get_recent_predictions(cls, model_name=None, limit=10):
        """ìµœê·¼ ì˜ˆì¸¡ ê²°ê³¼ ì¡°íšŒ"""
        try:
            username = session.get("username")
            password = session.get("password")

            if not username or not password:
                return None

            db = SQL(
                username=username, password=password, database="AOP_MLflow_Tracking"
            )

            if model_name:
                query = """
                    SELECT TOP (?)
                        model_name,
                        input_features,
                        prediction_result,
                        prediction_type,
                        prediction_timestamp,
                        user_id
                    FROM aop_prediction_logs
                    WHERE model_name = ?
                    ORDER BY prediction_timestamp DESC
                """
                result = db.execute_query(query, (limit, model_name))
            else:
                query = """
                    SELECT TOP (?)
                        model_name,
                        input_features,
                        prediction_result,
                        prediction_type,
                        prediction_timestamp,
                        user_id
                    FROM aop_prediction_logs
                    ORDER BY prediction_timestamp DESC
                """
                result = db.execute_query(query, (limit,))

            return result

        except Exception as e:
            logging.error(f"Failed to get recent predictions: {e}")
            return None

    def load_model_from_db(
        self, model_name, prediction_type="intensity", version=None, stage="Production"
    ):
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë¸ì„ ë¡œë“œ

        Args:
            model_name (str): ê¸°ë³¸ ëª¨ë¸ëª… (ì˜ˆ: "XGBoost")
            prediction_type (str): ì˜ˆì¸¡ íƒ€ì… ('intensity', 'power', 'temperature')
            version (int, optional): íŠ¹ì • ë²„ì „, Noneì´ë©´ ìµœì‹  ë²„ì „
            stage (str): ëª¨ë¸ ìŠ¤í…Œì´ì§€ ("Production", "Staging", "None")

        Returns:
            object: ë¡œë“œëœ ëª¨ë¸ ê°ì²´, ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # 1. ì •ê·œí™”ëœ ëª¨ë¸ëª… ìƒì„±
            normalized_model_name = self._normalize_model_name(
                model_name, prediction_type
            )

            # 2. ëª¨ë¸ ë²„ì „ ì¡°íšŒ
            if version is not None:
                # íŠ¹ì • ë²„ì „ ì¡°íšŒ
                query = """
                    SELECT mv.model_binary, mv.compression_type, mv.checksum
                    FROM ml_model_versions mv
                    JOIN ml_registered_models rm ON mv.model_id = rm.model_id
                    WHERE rm.model_name = ? AND mv.version_number = ? AND mv.prediction_type = ?
                """
                params = (normalized_model_name, version, prediction_type)
            else:
                # ìŠ¤í…Œì´ì§€ë³„ ìµœì‹  ë²„ì „ ì¡°íšŒ
                query = """
                    SELECT TOP 1 mv.model_binary, mv.compression_type, mv.checksum
                    FROM ml_model_versions mv
                    JOIN ml_registered_models rm ON mv.model_id = rm.model_id
                    WHERE rm.model_name = ? AND mv.stage = ? AND mv.prediction_type = ?
                    ORDER BY mv.version_number DESC
                """
                params = (normalized_model_name, stage, prediction_type)

            result = self.db.execute_query(query, params)

            if result.empty:
                self.logger.warning(
                    f"No model found: {normalized_model_name}, prediction_type: {prediction_type}, "
                    f"version: {version}, stage: {stage}"
                )
                return None

            # 3. ëª¨ë¸ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì¶”ì¶œ
            model_data = result.iloc[0]
            binary_data = model_data["model_binary"]
            compression_type = model_data["compression_type"]
            checksum = model_data["checksum"]

            # 4. ì²´í¬ì„¬ ê²€ì¦
            if not self._verify_checksum(binary_data, checksum):
                self.logger.error(
                    f"Checksum verification failed for model: {normalized_model_name}"
                )
                return None

            # 5. ëª¨ë¸ ê°ì²´ ë³µì›
            model_object = self._deserialize_model(binary_data, compression_type)

            if model_object is not None:
                self.logger.info(
                    f"Model loaded from database: {normalized_model_name}, "
                    f"prediction_type: {prediction_type}"
                )

            return model_object

        except Exception as e:
            self.logger.error(f"Failed to load model from database: {e}")
            return None

    def load_best_model(self, prediction_type="intensity", stage="Production"):
        """
        ì˜ˆì¸¡ íƒ€ì…ì— ë”°ë¼ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë¡œë“œ

        Args:
            prediction_type (str): ì˜ˆì¸¡ íƒ€ì… ('intensity', 'power', 'temperature')
            stage (str): ëª¨ë¸ ìŠ¤í…Œì´ì§€ ("Production", "Staging", "None")

        Returns:
            object: ë¡œë“œëœ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ê°ì²´, ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # 1. í•´ë‹¹ ì˜ˆì¸¡ íƒ€ì…ì˜ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì¡°íšŒ
            query = """
                SELECT TOP 1 
                    rm.model_name,
                    mv.version_number,
                    mv.version_id,
                    mv.model_binary, 
                    mv.compression_type, 
                    mv.checksum,
                    mp.metric_value as test_score
                FROM ml_registered_models rm
                JOIN ml_model_versions mv ON rm.model_id = mv.model_id
                JOIN ml_model_performance mp ON mv.version_id = mp.model_version_id
                WHERE mv.prediction_type = ? 
                    AND mv.stage = ?
                    AND mp.metric_name = 'test_score'
                ORDER BY mp.metric_value DESC
            """

            result = self.db.execute_query(query, (prediction_type, stage))

            if result.empty:
                self.logger.warning(
                    f"No model found for prediction_type: {prediction_type}, stage: {stage}"
                )
                return None

            # 2. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ
            best_model = result.iloc[0]
            model_name = best_model["model_name"]
            version_number = best_model["version_number"]
            version_id = best_model["version_id"]
            binary_data = best_model["model_binary"]
            compression_type = best_model["compression_type"]
            checksum = best_model["checksum"]
            test_score = best_model["test_score"]

            # 3. ì²´í¬ì„¬ ê²€ì¦
            if not self._verify_checksum(binary_data, checksum):
                self.logger.error(
                    f"Checksum verification failed for best model: {model_name} v{version_number}"
                )
                return None

            # 4. ëª¨ë¸ ê°ì²´ ë³µì›
            model_object = self._deserialize_model(binary_data, compression_type)

            if model_object is not None:
                self.logger.info(
                    f"Best model loaded: {model_name} v{version_number}, "
                    f"prediction_type: {prediction_type}, test_score: {test_score:.4f}"
                )

                # ëª¨ë¸ ì •ë³´ì™€ í•¨ê»˜ ë°˜í™˜ (íŠœí”Œ í˜•íƒœ)
                return {
                    "model": model_object,
                    "model_name": model_name,
                    "version_number": version_number,
                    "version_id": version_id,
                    "test_score": test_score,
                    "prediction_type": prediction_type,
                }

            return None

        except Exception as e:
            self.logger.error(f"Failed to load best model: {e}")
            return None

    def _verify_checksum(self, binary_data, expected_checksum):
        """
        ë°”ì´ë„ˆë¦¬ ë°ì´í„°ì˜ ì²´í¬ì„¬ ê²€ì¦

        Args:
            binary_data (bytes): ë°”ì´ë„ˆë¦¬ ë°ì´í„°
            expected_checksum (str): ì˜ˆìƒ ì²´í¬ì„¬

        Returns:
            bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€
        """
        import hashlib

        try:
            actual_checksum = hashlib.md5(binary_data).hexdigest()
            return actual_checksum == expected_checksum
        except Exception as e:
            self.logger.error(f"Checksum verification error: {e}")
            return False

    def list_available_models(self, prediction_type=None):
        """
        ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ

        Args:
            prediction_type (str, optional): íŠ¹ì • ì˜ˆì¸¡ íƒ€ì…ìœ¼ë¡œ í•„í„°ë§

        Returns:
            pandas.DataFrame: ëª¨ë¸ ëª©ë¡ ì •ë³´
        """
        try:
            if prediction_type:
                query = """
                    SELECT 
                        rm.model_name,
                        mv.version_number,
                        mv.prediction_type,
                        mv.stage,
                        mv.description,
                        mv.creation_time
                    FROM ml_registered_models rm
                    JOIN ml_model_versions mv ON rm.model_id = mv.model_id
                    WHERE mv.prediction_type = ?
                    ORDER BY rm.model_name, mv.version_number DESC
                """
                params = (prediction_type,)
            else:
                query = """
                    SELECT 
                        rm.model_name,
                        mv.version_number,
                        mv.prediction_type,
                        mv.stage,
                        mv.description,
                        mv.creation_time
                    FROM ml_registered_models rm
                    JOIN ml_model_versions mv ON rm.model_id = mv.model_id
                    ORDER BY rm.model_name, mv.prediction_type, mv.version_number DESC
                """
                params = ()

            result = self.db.execute_query(query, params)
            return result

        except Exception as e:
            self.logger.error(f"Failed to list available models: {e}")
            return None
